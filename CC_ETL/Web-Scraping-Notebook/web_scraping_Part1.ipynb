{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 130%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    \n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!pip install pymongo\n",
    "!pip install lxml\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data hunting and gathering\n",
    "\n",
    "\n",
    "SOFTWARE REQUIREMENTS\n",
    "    \n",
    "    + mongoDB #download mongoDB (http://www.mongodb.org)\n",
    "    + selenium #pip install selenium\n",
    "    + pymongo #pip install pymongo\n",
    "    + lxml #pip install  lxml\n",
    "    + tweepy #pip install tweepy\n",
    "    \n",
    "NOT REQUIRED BUT USED IN ONE EXAMPLE: \n",
    "\n",
    "    + MPV via Homebrew (OSX) or mplayer in Linux.\n",
    "    \n",
    "OTHER UTILITIES\n",
    "\n",
    "    + If you are using Firefox browser you may need Firebug.\n",
    "\n",
    "CONTENTS\n",
    "\n",
    "+ Introduction and warm-up project: A web crawler\n",
    "     \n",
    "+ Using the API\n",
    "\n",
    "    + Retrieving Twitter data\n",
    "\n",
    "+ Creating our own web API: Scraping\n",
    "\n",
    "    + Understanding HTML and CSS\n",
    "    + CSS selectors\n",
    "    + XPath selectors\n",
    "    + Scraping dynamic content with Selenium    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is the basis of this course. Although we usually find it in well structured formats such as a spreadsheet resulting from our last experiment, or the collection of company records in a classical relational database, with the advent of internet new information sources have to be taken into account. However, these new sources are home of unstructured data. In this lecture several methods for retrieving data and storing it are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first introduce the big picture guiding this lecture. Whenever we want to retrieve data from a web site we should ask first if the web site is providing a simple way for that purpose. Many large sites such as google, facebook, twitter, etc, provide a **Application Programming Interface (API)** that can make data hunting easier. However, most of web sites do not have this interface. Even more, an API may not provide the desired information. In those cases we have to use **scraping** techniques. This means dealing with the raw information as it is provided to the web browser and code our data finding methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"border-radius:20px;\" src=\"./files/big_picture.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start connecting to the net and checking out how to retrieve a basic page. We will start using `urllib` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x10ff91780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "source = urlopen('http://google.com')#Let us check what is in\n",
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"es\"><head><meta content=\"Google.es permite acceder a la informaci\\xf3n mundial en castellano, catal\\xe1n, gallego, euskara e ingl\\xe9s.\" name=\"description\"><meta content=\"noodp\" name=\"robots\"><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\">(function(){window.google={kEI:\\'EXytXauYOsrgUeiAopgK\\',kEXPI:\\'0,1353747,5662,730,224,510,19,1046,2082,1070,377,207,1017,54,2133,10,169,544,270,68,97,161,281,310,503,75,81,50,347,84,51,1130569,1197750,329517,1294,12383,4855,32692,15247,867,28684,364,3319,5505,2433,5951,1119,2,578,728,2432,1361,4323,4968,773,2249,7649,214,6196,1719,1808,1976,2044,8604,305,1899,3398,2016,38,920,873,1217,2975,2736,48,3013,2,631,3240,414,7652,2884,20,317,1118,902,2128,1,369,2777,919,992,509,776,8,1216,1580,219,594,154,601,11,14,667,612,2212,202,323,5,1252,840,324,193,794,672,8,48,157,663,3438,260,52,1137,2,2063,606,1839,184,595,1182,520,1947,449,298,429,343,710,93,204,124,1286,14,84,336,81,1760,666,45,2201,438,14,22,133,1206,729,19,1039,3094,133,773,22,887,639,42,482,7,729,88,503,523,240,685,126,188,1691,38,1,418,2403,770,1842,3148,12,25,52,612,52,2056,531,4,499,44,170,2,365,585,455,517,312,213,1177,284,997,81,31,659,231,15,554,47,27,390,654,50,94,136,562,89,635,490,2092,850,159,137,751,151,137,123,133,56,2,423,196,118,40,130,12,18,124,125,123,288,482,444,143,219,185,350,1222,593,5879918,1805894,4194572,233,2799641,194,1382,549,333,444,1,2,80,1,900,583,9,304,1,8,1,2,2551,1,748,141,59,736,563,1,3759,56,341,1,96,2,7,2,1,1,1,1,1,3,7,2,6,2,5,1,2,15,16,2,2,2,15,33,2,1,16,5,1,2795612,21169984\\',authuser:0,kscs:\\'c9c918f0_EXytXauYOsrgUeiAopgK\\',kGL:\\'ES\\',kBL:\\'pOt4\\'};google.sn=\\'webhp\\';google.kHL=\\'es\\';google.jsfs=\\'Ffpdje\\';})();(function(){google.lc=[];google.li=0;google.getEI=function(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||google.kEI};google.getLEI=function(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b};google.https=function(){return\"https:\"==window.location.protocol};google.ml=function(){return null};google.time=function(){return(new Date).getTime()};google.log=function(a,b,e,c,g){if(a=google.logUrl(a,b,e,c,g)){b=new Image;var d=google.lc,f=google.li;d[f]=b;b.onerror=b.onload=b.onabort=function(){delete d[f]};google.vel&&google.vel.lu&&google.vel.lu(a);b.src=a;google.li=f+1}};google.logUrl=function(a,b,e,c,g){var d=\"\",f=google.ls||\"\";e||-1!=b.search(\"&ei=\")||(d=\"&ei=\"+google.getEI(c),-1==b.search(\"&lei=\")&&(c=google.getLEI(c))&&(d+=\"&lei=\"+c));c=\"\";!e&&google.cshid&&-1==b.search(\"&cshid=\")&&\"slh\"!=a&&(c=\"&cshid=\"+google.cshid);a=e||\"/\"+(g||\"gen_204\")+\"?atyp=i&ct=\"+a+\"&cad=\"+b+d+f+\"&zx=\"+google.time()+c;/^http:/i.test(a)&&google.https()&&(google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a};}).call(this);(function(){google.y={};google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};}).call(this);google.f={};var a=window.location,b=a.href.indexOf(\"#\");if(0<=b){var c=a.href.substring(b+1);/(^|&)q=/.test(c)&&-1==c.indexOf(\"#\")&&a.replace(\"/search?\"+c.replace(/(^|&)fp=[^&]*/g,\"\")+\"&cad=h\")};</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\\n</style><style>body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#36c}.q{color:#00c}.ts td{padding:0}.ts{border-collapse:collapse}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px arial,sans-serif}.gsfs{font:17px arial,sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}a.gb1,a.gb2,a.gb3,a.gb4{color:#11c !important}body{background:#fff;color:black}a{color:#11c;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#36c}a:visited{color:#551a8b}a.gb1,a.gb4{text-decoration:underline}a.gb3:hover{text-decoration:none}#ghead a.gb2:hover{color:#fff !important}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#eee;border:solid 1px;border-color:#ccc #999 #999 #ccc;height:30px}.lsbb{display:block}.ftl,#fll a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;border:none;color:#000;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top}.lsb:active{background:#ccc}.lst:focus{outline:none}</style><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\"></script></head><body bgcolor=\"#fff\"><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\">(function(){var src=\\'/images/nav_logo229.png\\';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\\nif (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\\n}\\n})();</script><div id=\"mngb\"> <div id=gbar><nobr><b class=gb1>B\\xfasqueda</b> <a class=gb1 href=\"http://www.google.es/imghp?hl=es&tab=wi\">Im\\xe1genes</a> <a class=gb1 href=\"http://maps.google.es/maps?hl=es&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=es&tab=w8\">Play</a> <a class=gb1 href=\"http://www.youtube.com/?gl=ES&tab=w1\">YouTube</a> <a class=gb1 href=\"http://news.google.es/nwshp?hl=es&tab=wn\">Noticias</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.es/intl/es/about/products?tab=wh\"><u>M\\xe1s</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.es/history/optout?hl=es\" class=gb4>Historial web</a> | <a  href=\"/preferences?hl=es\" class=gb4>Configuraci\\xf3n</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=es&passive=true&continue=http://www.google.com/\" class=gb4>Iniciar sesi\\xf3n</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div> </div><center><br clear=\"all\" id=\"lgpd\"><div id=\"lga\"><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"es\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><input style=\"color:#000;margin:0;padding:5px 8px 0 6px;vertical-align:top\" autocomplete=\"off\" class=\"lst\" value=\"\" title=\"Buscar con Google\" maxlength=\"2048\" name=\"q\" size=\"57\"></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Buscar con Google\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid1\" value=\"Voy a tener suerte\" name=\"btnI\" type=\"submit\"><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\">(function(){var id=\\'tsuid1\\';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\\nelse top.location=\\'/doodles/\\';};})();</script><input value=\"AAP1E1EAAAAAXa2KIZecW6Td4jdIKCKu9LOQa2FzyCnT\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=es&amp;authuser=0\">B\\xfasqueda avanzada</a><a href=\"/language_tools?hl=es&amp;authuser=0\">Herramientas del idioma</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(\"undefined\"!=typeof XMLHttpRequest)b=\"2\";else if(\"undefined\"!=typeof ActiveXObject){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(\"2\"==a&&-1==location.search.indexOf(\"&gbv=2\")){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div id=\"gac_scont\"></div><div style=\"font-size:83%;min-height:3.5em\"><br><div id=\"gws-output-pages-elements-homepage_additional_languages__als\"><style>#gws-output-pages-elements-homepage_additional_languages__als{font-size:small;margin-bottom:24px}#SIvCob{display:inline-block;line-height:28px;}#SIvCob a{padding:0 3px;}.H6sW5{display:inline-block;margin:0 2px;white-space:nowrap}.z4hgWe{display:inline-block;margin:0 2px}</style><div id=\"SIvCob\">Ofrecido por Google en:  <a href=\"http://www.google.com/setprefs?sig=0_dihCGZEFBSVNjxwhfSpF7wkY_54%3D&amp;hl=ca&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjr5KPThq3lAhVKcBQKHWiACKMQ2ZgBCAU\">catal\\xe0</a>    <a href=\"http://www.google.com/setprefs?sig=0_dihCGZEFBSVNjxwhfSpF7wkY_54%3D&amp;hl=gl&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjr5KPThq3lAhVKcBQKHWiACKMQ2ZgBCAY\">galego</a>    <a href=\"http://www.google.com/setprefs?sig=0_dihCGZEFBSVNjxwhfSpF7wkY_54%3D&amp;hl=eu&amp;source=homepage&amp;sa=X&amp;ved=0ahUKEwjr5KPThq3lAhVKcBQKHWiACKMQ2ZgBCAc\">euskara</a>  </div></div></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"fll\"><a href=\"/intl/es/ads/\">Programas de publicidad</a><a href=\"http://www.google.es/intl/es/services/\">Soluciones Empresariales</a><a href=\"/intl/es/about.html\">Todo acerca de Google</a><a href=\"http://www.google.com/setprefdomain?prefdom=ES&amp;prev=http://www.google.es/&amp;sig=K_FNVBcsLYVC-DAJZk08icbF259ZY%3D\">Google.es</a></div></div><p style=\"color:#767676;font-size:8pt\">&copy; 2019 - <a href=\"/intl/es/policies/privacy/\">Privacidad</a> - <a href=\"/intl/es/policies/terms/\">Condiciones</a></p></span></center><script nonce=\"gMfCKVKP9ZVgj+BhB5iNqg==\">(function(){window.google.cdo={height:0,width:0};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=\"CSS1Compat\"==c.compatMode?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}a&&b&&(a!=google.cdo.width||b!=google.cdo.height)&&google.log(\"\",\"\",\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI);}).call(this);})();(function(){var u=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.Q9vTP_q_yLA.O/m\\\\x3dsb_he,d/am\\\\x3dwAlsBg/d\\\\x3d1/rs\\\\x3dACT90oFO2-20qJQO84lfpvaMUnpg6f7Auw\\';setTimeout(function(){var a=document.createElement(\"script\");a.src=u;google.timers&&google.timers.load&&google.tick&&google.tick(\"load\",\"xjsls\");document.body.appendChild(a)},0);})();(function(){window.google.xjsu=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.Q9vTP_q_yLA.O/m\\\\x3dsb_he,d/am\\\\x3dwAlsBg/d\\\\x3d1/rs\\\\x3dACT90oFO2-20qJQO84lfpvaMUnpg6f7Auw\\';})();function _DumpException(e){throw e;}\\nfunction _F_installCss(c){}\\n(function(){google.spjs=false;google.snet=true;google.em=[];google.emw=false;})();(function(){var pmc=\\'{\\\\x22CaHQXQ\\\\x22:{},\\\\x22Qnk92g\\\\x22:{},\\\\x22RWGcrA\\\\x22:{},\\\\x22U5B21g\\\\x22:{},\\\\x22YFCs/g\\\\x22:{},\\\\x22ZI/YVQ\\\\x22:{},\\\\x22d\\\\x22:{},\\\\x22mVopag\\\\x22:{},\\\\x22sb_he\\\\x22:{\\\\x22agen\\\\x22:true,\\\\x22cgen\\\\x22:true,\\\\x22client\\\\x22:\\\\x22heirloom-hp\\\\x22,\\\\x22dh\\\\x22:true,\\\\x22dhqt\\\\x22:true,\\\\x22ds\\\\x22:\\\\x22\\\\x22,\\\\x22ffql\\\\x22:\\\\x22es\\\\x22,\\\\x22fl\\\\x22:true,\\\\x22host\\\\x22:\\\\x22google.com\\\\x22,\\\\x22isbh\\\\x22:28,\\\\x22jsonp\\\\x22:true,\\\\x22lm\\\\x22:true,\\\\x22msgs\\\\x22:{\\\\x22cibl\\\\x22:\\\\x22Borrar b\\xfasqueda\\\\x22,\\\\x22dym\\\\x22:\\\\x22Quiz\\xe1s quisiste decir:\\\\x22,\\\\x22lcky\\\\x22:\\\\x22Voy a tener suerte\\\\x22,\\\\x22lml\\\\x22:\\\\x22M\\xe1s informaci\\xf3n\\\\x22,\\\\x22oskt\\\\x22:\\\\x22Herramientas de introducci\\xf3n de texto\\\\x22,\\\\x22psrc\\\\x22:\\\\x22Esta b\\xfasqueda se ha eliminado de tu \\\\\\\\u003Ca href\\\\x3d\\\\\\\\\\\\x22/history\\\\\\\\\\\\x22\\\\\\\\u003Ehistorial web\\\\\\\\u003C/a\\\\\\\\u003E.\\\\x22,\\\\x22psrl\\\\x22:\\\\x22Eliminar\\\\x22,\\\\x22sbit\\\\x22:\\\\x22Buscar por imagen\\\\x22,\\\\x22srch\\\\x22:\\\\x22Buscar con Google\\\\x22},\\\\x22ovr\\\\x22:{},\\\\x22pq\\\\x22:\\\\x22\\\\x22,\\\\x22refpd\\\\x22:true,\\\\x22rfs\\\\x22:[],\\\\x22sbpl\\\\x22:24,\\\\x22sbpr\\\\x22:24,\\\\x22scd\\\\x22:10,\\\\x22sce\\\\x22:5,\\\\x22stok\\\\x22:\\\\x22MaQQRG7yq7R9bldfI3vfBTQ3xhA\\\\x22,\\\\x22uhde\\\\x22:false}}\\';google.pmc=JSON.parse(pmc);})();</script>        </body></html>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hurray we got a socket. An all sockets behave like files, so let us go read() the \"file\"\n",
    "something = source.read()\n",
    "something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n"
     ]
    }
   ],
   "source": [
    "#What!!!!\n",
    "#Let us read more\n",
    "print (source.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ooooppss nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, hands on!!! \n",
    "Some first warm up exercises. Check the str api of python!\n",
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**WARM UP EXERCISES**\n",
    "<ol>\n",
    "<li>Is there the word python in pyladies.org?(hint: find python in source) </li>\n",
    "<li>Does http://google.com contain an image? (hint: < img  TAG ) </li>\n",
    "<li>What are the first ten characters of python.org?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n\\n<html>\\n<head>\\n    \\n    <title>PyLadies &ndash; Women Who Love Coding in Python</title>\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\"/>\\n    <link rel=\"stylesheet\" href=\"/assets/css/pygments.css\" media=\"screen\" title=\"screen\"/>\\n    <link rel=\"stylesheet\" href=\"/assets/css/screen.css\" media=\"screen\" title=\"screen\"/>\\n    <link rel=\"stylesheet\" href=\"/assets/css/mailchimp.css\" media=\"screen\" title=\"screen\"/>\\n    <link href=\\'https://fonts.googleapis.com/css?family=Glegoo|Bitter|Droid+Serif:400,700,400italic,700italic|Raleway:400,200,300,500,600,700\\' rel=\\'stylesheet\\' type=\\'text/css\\'/>\\n    <link rel=\"shortcut icon\" href=\"/assets/images/favicon.ico\" type=\"image/ico\" />\\n    <link rel=\"alternate\" type=\"application/atom+xml\" title=\"Atom 1.0\" href=\"http://pyladies.com/feed.xml\" />\\n    <script src=\"//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js\"></script>\\n    <script>if (window.location.protocol != \"https:\" && window.location.host.indexOf(\\'pyladies.com\\') > -1) {\\n      window.location.protocol = \"https\";\\n    }</script>\\n\\t\\n    <script src=\"https://platform.twitter.com/widgets.js\" type=\"text/javascript\"></script>\\n    <script type=\"text/javascript\" src=\"/assets/js/meetup_widget.js\"></script>\\n    <script type=\"text/javascript\">\\n        $(document).ready(function() {\\n            var meetupIds = \"8160762,4507652,5947662,9301202,243646248,9206152,8623152,5160912,19719503,8401402,18320041,255599015,2292131,281140334,13320732,15507962,22260794,13995752,248903240,253185498,9042722,244079349,13106102,2288171,95771702,203416475,282890453,186995752,19669577,14872062,193620926,4576312,201759643,18600594,185065560,4808882,16760422,8161032,5089102,3604052,251524694,5411282,10708842,19180337,14910222,7660062,18987204,14748112,6488102,18607403,7538042,2292131,201759643\";\\n             var timepadPages = \"135287\";\\n            PyladiesMeetupWidget.addUpcomingMeetups(meetupIds, timepadPages);\\n        });\\n\\t</script>\\n\\t\\n\\t\\n\\t\\n</head>\\n\\n<body>\\n    <a href=\"https://github.com/pyladies/pyladies\" class=\"github-corner\"><svg width=\"80\" height=\"80\" viewBox=\"0 0 250 250\" style=\"fill:rgb(255, 100, 100); color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);\"><path d=\"M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z\"></path><path d=\"M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2\" fill=\"currentColor\" style=\"transform-origin: 130px 106px;\" class=\"octo-arm\"></path><path d=\"M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z\" fill=\"currentColor\" class=\"octo-body\"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>\\n    <div class=\"header\">\\n        <div id=\"pyladies_header_logo\">\\n            <a href=\"/\"><img src=\"/assets/images/pyladies_logo.png\" width=\"260\" height=\"120\" alt=\"PyLadies Logo\"/></a>\\n        </div>\\n        <nav>\\n            <ul class=\"nav-wrapper\">\\n                <li><a href=\"/\">Home</a></li>\\n                <li><a href=\"/about/\">About</a></li>\\n                <li><a href=\"https://discuss.pyladies.com\">Forum</a></li>\\n                <li><a href=\"/locations/\">Locations</a></li>\\n                <li><a href=\"https://blog.pyladies.com\">Blog</a></li>\\n                <li><a href=\"/CodeOfConduct/\">Code of Conduct</a></li>\\n                <li><a href=\"/resources/\">Resources</a></li>\\n                <li><a href=\"/cdn-cgi/l/email-protection#d7beb9b1b897a7aebbb6b3beb2a4f9b4b8bae8a4a2b5bdb2b4a3ea9fb2bbbbb8\" id=\"contact-link\">Contact</a></li>\\n                <li><a href=\"http://pyladies.com/feed.xml\" title=\"RSS\">RSS</a></li>\\n            </ul>\\n        </nav>\\n    </div>\\n    <div class=\"page\">\\n        \\n    <h1 id=\"homepage_h1\">Welcome!</h1>\\n    <section id=\"archive\">\\n        <article class=\"welcome\">\\n            <div id=\"welcome_message\">\\n                    <h2>Welcome!</h2>\\n                    <img src=\"/assets/images/pylady_geek.png\" alt=\"Pyladies lady graphic\" />\\n                    <p>We are an international mentorship group with a focus on helping more women become active participants and leaders in the Python open-source community. Our mission is to promote, educate and advance a diverse Python community through outreach, education, conferences, events and social gatherings.</p>\\n                    <p>PyLadies also aims to provide a friendly support network for women and a bridge to the larger Python world. Anyone with an interest in Python is encouraged to participate!</p>\\n            </div>\\n        </article>\\n\\n        <article class=\"latest\">\\n            <h3 class=\"latest-master\">Latest Blog Posts</h3>\\n                <div id=\"latestBlog\">\\n                    \\n                        <h3><a href=\"/blog/Important-PyLadies-Update/important-pyladies-update/\">Important PyLadies Update</a></h3>\\n                        <time pubdate datetime=\"2019-08-15\">August 15, 2019</time>\\n                        <p>None  <a href=\"/blog/Important-PyLadies-Update/important-pyladies-update/\" class=\\'more-link\\'>Read more &rarr;</a></p>\\n                    \\n                        <h3><a href=\"/blog/EuroPython-2016-a-first-time-participants-thoughts/europython-recap/\">EuroPython 2016, a first time participant\\'s thoughts!</a></h3>\\n                        <time pubdate datetime=\"2016-08-01\">August 01, 2016</time>\\n                        <p>EuroPython wrapped up July 24th in Bilbao, Spain. As a first time <a href=\"https://twitter.com/loooorenanicole/status/755056966360326144\">participant</a> I was thrilled to attend, speak, and represent the PSF as a member of the Board of Directors!  <a href=\"/blog/EuroPython-2016-a-first-time-participants-thoughts/europython-recap/\" class=\\'more-link\\'>Read more &rarr;</a></p>\\n                    \\n                </div>\\n        </article>\\n    </section>\\n\\n\\n    </div>\\n\\n\\t<div class=\"sidebar\">\\n\\t\\t\\n        <div id=\"mc_embed_signup\">\\n            <form action=\"https://pyladies.us2.list-manage1.com/subscribe/post?u=9d20e0bc6bc0e88a076738c6f&amp;id=23e4f35e45\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\\n                <label for=\"mce-EMAIL\">Keep up with what\\'s going in the PyLadies community on our low-volume announcement list.  Men and women from everywhere are welcome.  Unsubscribe anytime. </label>\\n                <input type=\"email\" value=\"\" name=\"EMAIL\" class=\"email\" id=\"mce-EMAIL\" placeholder=\"email address\" required>\\n                <div class=\"clear\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\"></div>\\n            </form>\\n        </div>\\n\\n        <div id=\"sponsor_us_btn\"><a href=\"/sponsor/\">Sponsor Us</a></div>\\n\\n        <div id=\"shirts_btn\" style=\"display:flex;justify-content:center;align-items:center;font-size:14px;\"><a href=\"https://pyladies.spreadshirt.com/\">Get Swag</a></div>\\n\\n        <div id=\"stickers_btn\" style=\"display:flex;justify-content:center;align-items:center;font-size:14px;\"><a href=\"https://www.stickermule.com/user/1070441144/stickers\">Buy Stickers</a></div>\\n\\n        <h3>Upcoming Meetups</h3>\\n        <div id=\"upcomingMeetupsList\">\\n        </div>\\n\\n        <div id=\"twitter_feed\">\\n            <h3>Recent Tweets</h3>\\n            <div id=\"chapter_tweets\">\\n                <a width=\"400\" height=\"400\" class=\"twitter-timeline\" href=\"https://twitter.com/pyladies/lists/pyladies-locations\" data-widget-id=\"635861904234258433\">Tweets from https://twitter.com/pyladies/lists/pyladies-locations</a>\\n                <script data-cfasync=\"false\" src=\"/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js\"></script><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?\\'http\\':\\'https\\';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+\"://platform.twitter.com/widgets.js\";fjs.parentNode.insertBefore(js,fjs);}}(document,\"script\",\"twitter-wjs\");</script>\\n            </div>\\n\\t\\t</div>\\n\\t\\t\\n    </div>\\n\\n    <div class=\"footer-wrapper\">\\n            <footer id=\"bottom\">\\n\\t\\t\\t\\n                <ul class=\"social\">\\n                    <li><a class=\"icon google-plus\" data-icon=\"&#62223;\" href=\"https://plus.google.com/communities/108807002736066163985\" title=\"Google+\"></a></li>\\n                    <li><a class=\"icon github\" data-icon=\"&#62208;\" href=\"https://github.com/pyladies\" title=\"GitHub\"></a></li>\\n                    <li><a class=\"icon rss\" data-icon=\"&#59194;\" href=\"http://pyladies.com/feed.xml\" title=\"RSS\"></a></li>\\n                    <li><a class=\"icon creative-commons\" data-icon=\"&#128325;\" href=\"https://creativecommons.org/licenses/by-sa/3.0/\" title=\"Creative Commons\"></a></li>\\n                    <ul class=\"footer-notice\">\\n                        <li>2007 - 2019 PyLadies. All Rights Reserved.</li>\\n                        <li>Disclaimer - PyLadies and the PyLadies logo are trademarks of the Python Software Foundation</li>\\n                    </ul>\\n                </ul>\\n            \\n            </footer>\\n    </div>\\n\\n    <script type=\"text/javascript\">\\n\\n      var _gaq = _gaq || [];\\n      _gaq.push([\\'_setAccount\\', \\'UA-36930002-1\\']);\\n      _gaq.push([\\'_trackPageview\\']);\\n\\n      (function() {\\n        var ga = document.createElement(\\'script\\'); ga.type = \\'text/javascript\\'; ga.async = true;\\n        ga.src = (\\'https:\\' == document.location.protocol ? \\'https://ssl\\' : \\'http://www\\') + \\'.google-analytics.com/ga.js\\';\\n        var s = document.getElementsByTagName(\\'script\\')[0]; s.parentNode.insertBefore(ga, s);\\n      })();\\n\\n    </script>\\n\\n</body>\\n</html>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your code here \n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "# source = urlopen('http://pyladies.org').read()\n",
    "url = \"http://pyladies.com\"\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
    "request = urllib.request.Request(url,headers={'User-Agent': user_agent})\n",
    "response = urllib.request.urlopen(request)\n",
    "html = response.read()\n",
    "html\n",
    "# result = \"1: -\"\n",
    "# print (result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-15-8e4fd3c813ca>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-8e4fd3c813ca>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    url = 'http://pyladies.com''\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "source = urlopen('http://pyladies.com').read()\n",
    "req.add_header('User-agent','Mozilla')\n",
    "result = \"1: -\"\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iso-8859-1\n",
      "2: -\n"
     ]
    }
   ],
   "source": [
    "#Write your code here \n",
    "from urllib.request import urlopen\n",
    "source = urlopen('http://google.com')\n",
    "encoding = source.headers.get_content_charset()\n",
    "if encoding is None:\n",
    "    encoding=\"utf-8\"\n",
    "print(encoding)\n",
    "result = \"2: -\"\n",
    "print (result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: - \n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "source = urlopen('http://google.com').read()\n",
    "\n",
    "print (\"3: - \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are retrieving data from an URL! So we are done! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling and Scraping\n",
    "\n",
    "Scraping and **crawling** are two very related techniques. While scraping is used for retrieving data from a web page, crawling is used to retrieve the web pages. Scraping and crawling are found at the core of search engines. Scraping is used to get keywords, analyze, and extract useful information from the web pages so that given a user query it may return related results. On the other hand, crawling allows to retrieve the actual pages and uses scraping to get the links in each web site. This allows to create a graph of the connection among web sites and this information can be used to order the results of a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we might want not only to get data from a single page but probably retrieve from several related pages. In those cases crawling is the way to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">**WARM-UP PROJECT:** Let us build a very simple spider. The basic functionality of an spider is to crawl and store all the data in web pages. In this simple project we will take care of single site. \n",
    "\n",
    "<ol>\n",
    "<li>A crawler must recognize the links to crawl. Take a minute and think how to retrieve the links of a web site.</li>\n",
    "<li>Let us start the project by creating a Spider class. The constructor will have the following parameters: starting_url, crawl_domain, and max_iter. crawl_domain will be the domain that validates if an absolute link will be considered or not. max_iter is the maximum amount of web items to crawl.</li>\n",
    "<li>The main method can be Spider.run(). Enumerate the big functionalities/building blocks of the crawler.</li>\n",
    "</ol>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import time\n",
    "\n",
    "def getLinks(html, max_links=10):\n",
    "    url = []\n",
    "    cursor = 0\n",
    "    nlinks=0\n",
    "    while (cursor>=0 and nlinks<max_links):\n",
    "        start_link = html.find(\"a href\",cursor)\n",
    "        if start_link==-1:\n",
    "            return url\n",
    "        start_quote = html.find('\"', start_link)\n",
    "        end_quote = html.find('\"', start_quote + 1)\n",
    "        url.append(html[start_quote + 1: end_quote])\n",
    "        cursor = end_quote+1\n",
    "        nlinks = nlinks +1\n",
    "    return url\n",
    "\n",
    "class Spider:\n",
    "    def __init__(self,starting_url,crawl_domain,max_iter):\n",
    "        self.crawl_domain = crawl_domain\n",
    "        self.max_iter = max_iter\n",
    "        self.links_to_crawl=[]\n",
    "        self.links_to_crawl.append(starting_url)\n",
    "        self.links_visited=[]\n",
    "        self.collection=[]\n",
    "        \n",
    "    def retrieveHtml(self):\n",
    "        try:\n",
    "            socket = urllib.request.urlopen(self.url);\n",
    "            encoding =   socket.headers.get_content_charset()\n",
    "            if encoding is None:\n",
    "                    encoding = \"utf-8\"\n",
    "            self.html = socket.read().decode(encoding)\n",
    "            return 0\n",
    "        except UnicodeDecodeError:\n",
    "            print (\"Bad Encoding\")\n",
    "            return -1\n",
    "        except urllib.error.HTTPError:\n",
    "            # Most probably an url not found 404, possibly due to malformating of the links in retrieveAndValidateLinks\n",
    "            print (\"Broken Link\")\n",
    "            return -1\n",
    "    def storeHtml(self):\n",
    "        doc = {}\n",
    "        doc['url'] = self.url\n",
    "        doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "        doc['html'] = self.html\n",
    "        self.collection.append(doc)          \n",
    "   \n",
    "    def retrieveAndValidateLinks(self):\n",
    "        tmpList=[]\n",
    "        items = getLinks(self.html)\n",
    "        # Check the validity of a link\n",
    "        for item in items:\n",
    "            item = item.strip('\"')\n",
    "            if self.crawl_domain in item:\n",
    "                tmpList.append(item)\n",
    "            if not(\":\") in item: #Take care of http:// https:// and mailto:\n",
    "                tmpList.append(self.crawl_domain+item)\n",
    "        # Check that the link has not been previously retrieved or is currently on the links_to_crawl list\n",
    "        for item in tmpList:\n",
    "            if item not in self.links_visited:\n",
    "                if item not in self.links_to_crawl:\n",
    "                    self.links_to_crawl.append(item)\n",
    "                    print ('Adding: '+item)\n",
    "                \n",
    "     \n",
    "        \n",
    "    def run(self):\n",
    "        while (len(self.links_to_crawl)>0 and len(self.collection)<self.max_iter):\n",
    "            \n",
    "            self.url = self.links_to_crawl.pop(0)\n",
    "            print (\"Visiting: \"+ self.url)\n",
    "            self.links_visited.append(self.url)\n",
    "            if self.retrieveHtml()>=0:\n",
    "                self.storeHtml()\n",
    "                self.retrieveAndValidateLinks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us validate the crawler with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting: http://www.esade.edu\n",
      "Adding: http://www.esade.edu#main-content\n",
      "Adding: http://www.esade.edu/en\n",
      "Adding: http://www.esade.edu/ca\n",
      "Adding: http://www.esade.edu/es\n",
      "Adding: http://www.esade.edu/en/contact\n",
      "Adding: http://www.esade.edu/en/about-us\n",
      "Adding: http://www.esade.edu/en/about-us/what-is-ESADE\n",
      "Visiting: http://www.esade.edu#main-content\n",
      "Visiting: http://www.esade.edu/en\n",
      "Visiting: http://www.esade.edu/ca\n",
      "Adding: http://www.esade.edu/ca/contacte\n",
      "Adding: http://www.esade.edu/ca/coneix-esade\n",
      "Adding: http://www.esade.edu/ca/coneix-esade/que-es-Esade\n",
      "Visiting: http://www.esade.edu/es\n",
      "Adding: http://www.esade.edu/es/contacto\n",
      "Adding: http://www.esade.edu/es/conoce-esade\n",
      "Adding: http://www.esade.edu/es/conoce-esade/que-es-ESADE\n",
      "Visiting: http://www.esade.edu/en/contact\n",
      "Visiting: http://www.esade.edu/en/about-us\n",
      "Visiting: http://www.esade.edu/en/about-us/what-is-ESADE\n",
      "Visiting: http://www.esade.edu/ca/contacte\n",
      "Visiting: http://www.esade.edu/ca/coneix-esade\n",
      "Visiting: http://www.esade.edu/ca/coneix-esade/que-es-Esade\n",
      "Visiting: http://www.esade.edu/es/contacto\n",
      "Visiting: http://www.esade.edu/es/conoce-esade\n",
      "Visiting: http://www.esade.edu/es/conoce-esade/que-es-ESADE\n"
     ]
    }
   ],
   "source": [
    "spider = Spider('http://www.esade.edu','http://www.esade.edu',20)\n",
    "spider.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us go for a more complex web site. Run the code on http://hunch.net (a machine learning blog by John Langford)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting: http://hunch.net\n",
      "Adding: http://hunch.net/\n",
      "Adding: http://hunch.net/?p=12224166\n",
      "Adding: http://hunch.net/?cat=11\n",
      "Adding: http://hunch.net/?cat=41\n",
      "Adding: http://hunch.net/~jl\n",
      "Visiting: http://hunch.net/\n",
      "Visiting: http://hunch.net/?p=12224166\n",
      "Visiting: http://hunch.net/?cat=11\n",
      "Visiting: http://hunch.net/?cat=41\n",
      "Visiting: http://hunch.net/~jl\n",
      "Adding: http://hunch.netpublic_key\n",
      "Adding: http://hunch.net/~mltf\n",
      "Adding: http://hunch.net/~rwil\n",
      "Adding: http://hunch.netprojects/projects.html\n",
      "Adding: http://hunch.netconferences/conferences.html\n",
      "Adding: http://hunch.netclasses/classes.html\n",
      "Adding: http://hunch.netresume/resume.html\n",
      "Visiting: http://hunch.netpublic_key\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1317\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 928\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-25591b6e4c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mspider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://hunch.net'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'http://hunch.net'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-15e62ca944c3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Visiting: \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks_visited\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieveHtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoreHtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieveAndValidateLinks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-15e62ca944c3>\u001b[0m in \u001b[0;36mretrieveHtml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mretrieveHtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0msocket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m   \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_content_charset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "spider = Spider('http://hunch.net','http://hunch.net',10)\n",
    "spider.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And check the urls retrieved\n",
    "[spider.collection[i]['url'] for i in range(len(spider.collection))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the simple crawler more or less works as expected. There are still many functionalities to work on , such as valid domains, valid urls, etc. One important issue to consider is **persistence**, or how to store the data retrieved for further analysis. In this basic scraping tutorial we us MongoDB as a Non-SQL database for persistence purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Finishing the warm up project with MongoDB storage\n",
    "\n",
    "We just have to change two lines of code ... literally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import time\n",
    "import pymongo\n",
    "\n",
    "def getLinks(html, max_links=10):\n",
    "    url = []\n",
    "    cursor = 0\n",
    "    nlinks=0\n",
    "    while (cursor>=0 and nlinks<max_links):\n",
    "        start_link = html.find(\"a href\",cursor)\n",
    "        if start_link==-1:\n",
    "            return url\n",
    "        start_quote = html.find('\"', start_link)\n",
    "        end_quote = html.find('\"', start_quote + 1)\n",
    "        url.append(html[start_quote + 1: end_quote])\n",
    "        cursor = end_quote+1\n",
    "        nlinks = nlinks +1\n",
    "    return url\n",
    "\n",
    "class Spider:\n",
    "    def __init__(self,starting_url,crawl_domain,max_iter):\n",
    "        self.crawl_domain = crawl_domain\n",
    "        self.max_iter = max_iter\n",
    "        self.links_to_crawl=[]\n",
    "        self.links_to_crawl.append(starting_url)\n",
    "        self.links_visited=[]\n",
    "        try:\n",
    "            #use your database name, user and password here:\n",
    "            #mongodb://<dbuser>:<dbpassword>@<mlab_url>/<database_name>\n",
    "            with open(\"credentials.txt\", 'r', encoding='utf-8') as f:\n",
    "                [name,password,url,dbname]=f.read().splitlines()\n",
    "                self.conn=pymongo.MongoClient(\"mongodb://{}:{}@{}/{}\".format(name,password,url,dbname))\n",
    "            print (\"Connected successfully!!!\")\n",
    "        except pymongo.errors.ConnectionFailure as e:\n",
    "            print (\"Could not connect to MongoDB: %s\" % e) \n",
    "        self.db = self.conn['cloudcomputing']\n",
    "        self.collection = self.db[starting_url[7:]+'DB']\n",
    "        \n",
    "    def retrieveHtml(self):\n",
    "        try:\n",
    "            socket = urllib.request.urlopen(self.url);\n",
    "            encoding = socket.headers.get_content_charset()\n",
    "            if encoding is None:\n",
    "                    encoding = \"utf-8\"\n",
    "            self.html = socket.read().decode(encoding)\n",
    "            return 0\n",
    "        except UnicodeDecodeError:\n",
    "            print (\"Bad Encoding\")\n",
    "            return -1\n",
    "        except urllib.error.HTTPError:\n",
    "            # Most probably an url not found 404, possibly due to malformating of the links in retrieveAndValidateLinks\n",
    "            print (\"Broken Link\")\n",
    "            return -1\n",
    "    def storeHtml(self):\n",
    "        doc = {}\n",
    "        doc['url'] = self.url\n",
    "        doc['date'] = time.strftime(\"%d/%m/%Y\")\n",
    "        doc['html'] = self.html\n",
    "        #Insert in the collection\n",
    "        self.collection.insert_one(doc)        \n",
    "   \n",
    "    def retrieveAndValidateLinks(self):\n",
    "        tmpList=[]\n",
    "        items = getLinks(self.html)\n",
    "        # Check the validity of a link\n",
    "        for item in items:\n",
    "            item = item.strip('\"')\n",
    "            if self.crawl_domain in item:\n",
    "                tmpList.append(item)\n",
    "            if not(\":\") in item: #Take care of http:// https:// and mailto:\n",
    "                tmpList.append(self.crawl_domain+item)\n",
    "        # Check that the link has not been previously retrieved or is currently on the links_to_crawl list\n",
    "        for item in tmpList:\n",
    "            if item not in self.links_visited:\n",
    "                if item not in self.links_to_crawl:\n",
    "                    self.links_to_crawl.append(item)\n",
    "                    print ('Adding: '+item)\n",
    "                \n",
    "     \n",
    "        \n",
    "    def run(self):\n",
    "        #Change the count on the collection\n",
    "  \n",
    "        while (len(self.links_to_crawl)>0 and self.collection.count()<self.max_iter):   \n",
    "            self.url = self.links_to_crawl.pop(0)\n",
    "            print (\"Visiting: \"+ self.url)\n",
    "            self.links_visited.append(self.url)\n",
    "            if self.retrieveHtml()>=0:\n",
    "                self.storeHtml()\n",
    "                self.retrieveAndValidateLinks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spider = Spider('http://www.esade.edu','http://www.esade.edu',20)\n",
    "spider.run()\n",
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the collection:\n",
    "\n",
    "https://mlab.com/databases/cloudcomputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spider.db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = spider.db['www.esade.eduDB']\n",
    "collection.count()\n",
    "#spider.db.drop_collection(\"www.esade.eduDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in collection.find():\n",
    "    print (\"[{}] {}\".format(doc['date'], doc['url']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "**PROS and CONS:**\n",
    "<p>\n",
    "**MongoDB** querying is powerful but based on basic string operations. This actually tells us that storing full HTML pages is not going to be effiecient for retrieval. Actually, we will see that it is important to break the information in the pieces we really want. However, this is a good starting point before a post processing if we are not sure what we are going to do with the data or further scraping is going to take long. </p>\n",
    "</div>\n",
    "\n",
    "In the next section we will see more efficient ways of dealing with web based data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "\n",
    "**URLLIB** is good for getting simple things. In the end you end up with a large HTML string you want to do something on it. \n",
    "So the next thing you want to do is to parse data. But you want to do it in the same way you do when you interact with the web page. You see a menu, a frame on the left side, a nice colorful block where the price for your flight is. So **you want to parse data the way you see data in the webpage so that you can target it**.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
